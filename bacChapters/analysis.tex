%contents:
%- literature studies
%- analysis
%- comparison and summary of existing approaches

Exploring volume data and polygonal meshes is a complex task. Every research has different points or \emph{regions-of-interest} (ROI) and the methods to reveal those regions depend on the purpose of the study. Hence, regions are classified by their \emph{degree-of-interest} function (DOI)~\cite{proc:intelligentCutaway}. A high DOI means a region is of high interest, a low DOI stands for a region of secondary interest.

There are three common methods for revealing occluded structures of an object:
\begin{itemize}
	\item Transparency/Ghosted views
	\item Cut-away views
	\item Exploded views
\end{itemize}

\section{Transparency/Ghosted views}
These techniques do not discard any parts of displayed objects but let them vanish to a certain degree. Hence, it lowers the opacity of certain data points. For example, the opacity of the outer structure of an object is decreased so that the inner structure is revealed~\cite{jour:correa}. Increasing the transparency of occluding parts makes ROIs visible but at the same time makes it difficult to distinguish the several semi-transparent layers and identify their spatial composition~\cite{jour:interactiveCutaway}.

Bruckner and Gr{\"o}ller~\cite{proc:volumeshop} use a ghost object explicitly to preserve the context of illustrations. When the user defines a ROI, several transformations can be applied to it while at the original position, a faded version of the ROI will be visible. In their work, Bruckner and Gr{\"o}ller describe a method with weighted membership functions for the background, ghost and selection respectively to define the color of the resulting illustration. The opacity for a point is determined by the grade of membership in the union of all sets.

\section{Cut-away views}
Cut-away views, also called cutaways, reveal ROIs that are occluded by objects of secondary interest. The latter are cut out in order to make the ROI visible~\cite{proc:volumeshop}\cite{jour:adaptiveCutaways}\cite{jour:correa}\cite{incoll:cutawayIllustration}. Omitting the occluding regions increases comprehension of spatial relationships between the components. Also, the position and orientation of ROIs are shown in context of their surrounding structures~\cite{jour:interactiveCutaway}.

Li et al.~\cite{jour:interactiveCutaway} present a method based on the ideas that cuts are made in respect to their geometry and that interactive exploration of the 3D models is strongly supported. Removing parts of the object is handled carefully so that the user can mentally reconstruct the missing geometry. Additionally, the cuts are view dependent. The farther a structure is away from the viewpoint, the less is it cut. To increase interactivity the viewpoint and the cutting parameters can be controlled by the user. Li et al. state that low-level controls like cutting planes that need to be precisely positioned require a certain expertise from the user to reveal ROIs and thus should not be used. In their approach, users can set any viewpoint and dynamically manipulate the model with the mouse to define the ideal cut. Their system has two components. The authoring interface and the viewing interface. While the authoring interface enables the user to adjust a 3D model by several parameters, the viewing interface takes this adjusted model and lets the user explore it. The latter gives the user the choice between direct manipulation or the usage of high-level cutaway tools that automatically generate the cutaway. Cuts can be directly modified by interaction with the mouse. The cut is resized by snapping the nearest cutting face to a surface point, moving the position of the cut is possible either in only one dimension or in all three directions at once. Also, multiple cuts at once can be accomplished by the use of an occlusion graph\footnote{This is a graph generated in respect to the viewpoint that defines the number of occluding structures to be removed in order to become visible. An occlusion graph is assigned to each part of the model.}. The system updates all cuts by the inset constraints in both directions of the occlusion graph. A fast method to expand or collapse cuts is by cutting out or closing entire layers of structures. This can be achieved by clicking on a structure and all structures above or below in the occlusion graph are cut out or closed. Cross-sectional surfaces are exposed by changing the angle of the cuts. The degree of bevelling can be adjusted by the user with a slider. Subsequently, the faces of the revealed structures turn to the viewer automatically.

Higher-level interfaces involve algorithms for automatically exposing target structures that are pre-selected by the user. Therefore, the user selects a set of targets from a list. The system then determines the cutting parameters and a viewpoint. All parts of the cutting volume above a target structure in the occlusion graph are fully expanded, all parts below the target structure and the target structure itself are completely closed. This step assures a maximum exposure of the target structures. To preserve the context from occluding structures, the corresponding cutting volume of each non-target part is being closed as much as possible regarding the inset constraints and considering not to occlude target structures. For this step the algorithm traverses the occlusion graph upwards, starting at the leaves. After finishing those steps, all non-target structures are being desaturated to highlight the target structures.

An interesting approach for adaptive cutaways is presented by Burns and Finkelstein~\cite{jour:adaptiveCutaways}. Their method allows interactive rendering of adaptive cutaways. It ensures that objects of interest are not obscured by objects of secondary importance, so-called \emph{secondary objects}. Depending on the position and the projection of the camera, the cutaways have to be adapted to guarantee free sight of the objects of interest. The main part of the work is the depth image cutaway representation. It is based on an approximation of the \emph{chamfer distance transform} algorithm. The depth values of the rendered back hulls of the objects of interests are used as an input. The final result is a depth image containing the objects of interest and additional \emph{drill holes} around them with a certain slope depending on the camera position and projection. The depth buffer is used for an additional depth check in the fragment shader, but the OpenGL pipeline only supports one depth buffer. If a fragment of a secondary object has a depth value smaller than the depth value in the cutaway depth image, it is discarded, because it would occlude objects of interest. As a last step, the objects of interest are rendered without checking against the cutaway depth buffer. The cutaway depth image must be computed every frame to ensure interactive real-time cutaways. The approach has the following advantages:
\begin{itemize}
	\item the shape of the cutaways is defined by the silhouette of the objects of interest
	\item the cutaway surface is view dependent
	\item the angle that defines the slope of the drill holes around the objects of interest can be adapted
	\item multiple distant objects of interest have their own cutaways which can merge when the objects converge
\end{itemize}

Special attention is drawn to the rendering of the cut surfaces of secondary objects. Because the geometry is clipped, the secondary objects would have a hollow appearance. Therefore, fragments of back facing polygons of the secondary objects are shaded according to the normals of the cutaway shapes. As a result, the geometry cut appears as carved solid objects. Slightly fading out ghost lines of the silhouette of the clipped polygons additionally improve the perception of the embedment of the objects of interest.

Optimizing the visibility of important target sections by defining a DOI function is an approach introduced by Sigg et al.~\cite{proc:intelligentCutaway}. The user specifies a DOI function for either a polygonal mesh or volume data that assigns a value of importance to each vertex or voxel. Additionally, the shape and the maximum number of geometric primitives being cut out can be selected, but those cutting primitives should be limited to pre-defined shapes in order to be comprehensible. Sigg et al. provide the user with three kinds of shapes: cuboids, cylinders and spheres. Although the user can select the points of interest, the exact position and size of the cutting primitives is computed by the system. That means that the user roughly defines important regions while the optimization is done by the system. For the optimization, the resulting image from the renderer is used, what makes it easy to integrate it into existing rendering frameworks. The optimization process is iterative. The most important step is the image analysis with the objective function. It takes the viewing perspective into account. The image data is divided into two categories, positive for the important parts and negative for the unimportant parts. To achieve a maximum context for the ROIs the omitted data has to be minimized in those regions. The formula for maximizing the objective function~\ref{eq:objectiveFunction}.
\begin{equation}
f(A, P) \colon= \frac{1}{d} \sum^n_{i=1} (\alpha\cdot A_{i,pos} - A_{i,neg}) - \beta\cdot V(P)
\label{eq:objectiveFunction}
\end{equation}

\emph{A} is the image expressed in a pixel array of length \emph{d = width $\cdot$ height}. Each pixel has an important and an unimportant part, \emph{pos} and \emph{neg}. \emph{V(P)} measures the amount of omitted data of the set of cutting primitives \emph{P}. $\alpha$ and $\beta$ define the weighting of the importance of the target part and the surroundings. $\alpha$ regulates the importance of the target parts being shown, $\beta$ defines the importance for preserving the surroundings. In this approach, rendering settings like transparency and shading are preserved as only geometry of the object of secondary interest is removed.

Kn{\"o}del et al. present an approach with strong focus on user-modified cutaways~\cite{incoll:cutawayIllustration}. For cutting a model, they use four basic shapes: spheres, cubes, wedges and tubes. To perform the actual cut, they use the principle of \emph{Constructive Solid Geometry} (CSG)~\cite{book:computerGraphicsHearn}\cite{book:computerGraphicsHill} algorithms that creates the cut by intersecting shapes, taking the union of them or subtracting one shape of the other.

Cut-away views are also used in combination with ghosting. This means that the region cut out is replaced by a faded duplicate of the original. Features such as edges are attempted to be preserved. Therefore, the ghost stands for the original region before cutting~\cite{proc:volumeshop}.

\section{Exploded views}
An exploded view reveals the ROI by moving away the surrounding objects into multiple directions. In case inner structures need to be revealed, the jacket is decomposed into multiple parts before it is separated from the ROI. Also, cross-sections become visible~\cite{jour:explodedView}. The individual parts are separated from each other in respect to the global structure of the object as well as to the local spatial relationships~\cite{jour:generationExplodedView}. In contrast to ghosted views or cutaways, no contextual information gets lost, but it may come to visual clutter, if every single part of the object is exposed.

A system for creating and viewing interactive exploded views of complex 3D models is introduced by Li et al~\cite{jour:generationExplodedView}. Their aim is a system that allows users to explore the spatial relationships between specific ROIs. Target parts can be selected from a list in order to only expose the target parts and not showing anything else from the object. Thereafter, the parts can be directly expanded or collapsed to show a comprehensible spatial relationship. An iterative algorithm is used to remove unblocked parts from the model and adds them to an hierarchical, acyclic explosion graph\footnote{An explosion graph states the order in which parts can be exploded without blocking.}. Initially, all parts of the model are added to a set \emph{S}. At each iteration, those parts that are unblocked into at least one direction are determined and added to a set \emph{P}. Further on, a part \emph{p $\in$ P} is determined that requires the shortest distance to release itself from its adjunctive parts. Within the graph, \emph{p} is linked to its adjunctive parts with an edge and information about the direction of the release, the explosion direction, is stored. Finally, \emph{p} is removed from \emph{S}. When no more parts can be removed from \emph{S} the algorithm terminates and the explosion graph is complete. In case a part hierarchy exists, the explosion graph is divided into several overlapping sub-assemblies that allow independent expansion and collapse of a subset of parts of the model. For each sub-assembly an explosion graph is calculated by applying the algorithm described above. Interaction is guaranteed by direct user controls and higher-level interaction modes. The direct controls include animated expand and collapse, direct manipulation and riffling. With a click of the mouse, the model is fully exploded or entirely collapsed. This is done in reverse topological order with respect to the explosion graph to avoid that blocking constraints are violated. By dragging a part with the mouse cursor, it is slid into its explosion direction, continually updating its offset. In this way, selected parts can be examined in detail by gradually exploding or collapsing them. The blocking constraints are maintained constantly during the manipulation due to the system that checks for blocking parts within the explosion graph. If there is a blocking part found amongst the descendants, further explosion is inhibited. Riffling means that the parts explode when the mouse cursor slides over them. As long as the cursor moves over the part, it remains exploded. If the cursor moves on, the explosion is undone. A mouse click prompts the part to remain exploded. In this way, the user obtains a quick overview in what direction the parts of the model explode and how certain parts are assembled and connected to each other.

In the higher-level interaction mode the user-selected target parts to explode automatically. After the user chose the desired targets from a list of model parts, those target parts are labelled and exposed. All non-target parts are collapsed. This step is implemented with a smooth animation to assure traceability. Exposure is realized with either explosions or a combination of cutaways and explosions. Exploded views for non-hierarchical models have to meet two conditions. First, each part \emph{p} must not occlude any target part. Second, if \emph{p} is a target part itself, it must not be occluded by any other part. For this reason, each part of the explosion graph is visited in topological order. If necessary, \emph{p} is moved in order to not occlude any target part. Additionally, target parts are emphasized by encapsulation. That means they are separated from all touching parts. To combine cutaways and explosions, the selected target part is first exposed by a cutaway within its context, then moved away from the rest of the model through the cutaway hole and finally exploded to reveal all its details. For an effective cutaway, the explosion direction has to be determined before the translation and the cutaway hole has to be large enough to let the target part move through.

Bruckner and Gr{\"o}ller introduce a force-directed layout for exploded views of 3D information in their work about \emph{Exploded Views for Volume Data}~\cite{jour:explodedView}. In their approach, they divide the volume data into regions with a DOI~>~0, and regions with a DOI~=~0. All regions with a DOI~>~0 are part of the selection, the other regions belong to the background that represents the context. While the parts of the background are transformed, the selection remains static. The background is divided into a user-defined number of parts that do not intersect. Subsequently, those background parts are moved into different directions to reveal the selection. A parameter \emph{degree-of-explosion} (DOE) is introduced to allow the user to control how far the background is moved away from the selection. If the DOE equals zero, the background is not moved at all and clasps the selection. The higher the DOE, the farther the background parts are moved away from the selection. With the DOE, the view dependency can be reduced and spacing can be increased. Additionally, physical forces are simulated in a force-directed layout. All parts of the object are structured in a graph. Within this graph, repulsive forces are assigned to each node and attractive forces are assigned to adjacent nodes. The aim is to avoid conclusions completely by the minimum displacement. To achieve a steady state, all forces should be in equilibrium.

A number of forces are defined:
\begin{itemize}
	\item Return force
	\item Explosion force
	\item Viewing force
	\item Spacing force
\end{itemize}

The \emph{return force} attracts the background parts to their original location. The \emph{explosion force} pushes them off the selection object. The \emph{viewing force} causes the background parts to not occlude the selection for the current viewing transformation. This is essential, as the user can rotate the camera arbitrarily. Finally, the repulsive \emph{spacing force} prevents the parts from clustering. All forces, except the return force which remains constant, are scaled with the DOE parameter.


